# SceneCraft

The problem of generating 3D views from unstructured sets of 2D images is a long-running problem in computer graphics and vision. In the past decade, iterative methods of solving for the camera parameters from unstructured 2D view sets such as COLMAP (J. L. Sch√∂nberger and J.-M. Frahm, 2016)  have enabled novel methods of learning 3D representations, such as Neural Radiance Fields (NeRFs) (Mildenhall, Ben, et al. 2020). NeRFs generate camera rays, and fit them to the expected output values of the rays. This is essentially volume rendering with a neural network-learned volumetric function. One large flaw of these methods is that these learned functions can be exceedingly large and non-reusable. In this capstone project, we aim to efficiently generate small volumetric representations for different NeRF scenes without having to learn large independent networks. 
